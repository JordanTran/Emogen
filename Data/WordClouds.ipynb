{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37c39fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13d1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = STOPWORDS.union(open(r'/Users/zengspencer/Desktop/en_complete.txt')).union(\n",
    "    open(r'/Users/zengspencer/Desktop/stopwords-en.txt')\n",
    ").union(\n",
    "    {'fuck','shit','fucking','don','didn','wanna','gonna','damn','im','dont','go','need','today','wtf','Russia','putin',\n",
    "    'now','know','say','back','will','one','want','let','day','people','time','stop','even','still','really','us',\n",
    "    'right','got','good','see','man','make','going','bitch','yes','give','won','every','someone','re','come','always'\n",
    "    'getting','absolutely','ur','doesn','keep','already','another','trying','take','better','please','made','well'\n",
    "    'tell','said','exactly','think','well','much','oh','done','always','never','Work','Way','way','makes','first',\n",
    "    'Watch','Look','Getting'}.union(\n",
    "    {'getting','work','russia','wait','look','new','everyone','na','watch','tell','yet','must','put','something',\n",
    "    'many','yeah','believe'}).union(\n",
    "    {'nothing','everything','hey','isn','thing','anything','enough','sure','leave','away','needs','last','call',\n",
    "    'show','twitter','next','tweet','feel','home','wordle','country','ukraine','game','bro','person','year','world',\n",
    "    've','love'}).union(\n",
    "    {'guy','play','big','love','thank','looks','looking','thanks','okay','true','pls','miss','sorry','best','soon',\n",
    "    'real','hope','finally','happy','god','baby','literally','life','missed','dick','pussy','ass','feeling','fine','pretty','gotta',\n",
    "    'girl','wish','ain','days','guys','tho','ll','hard','thought','dey','nigga','sounds','boy','song','coming','morning','might',\n",
    "    'beautiful','years','though','ya','maybe','ok','nice','night','sir','welcome','actually','seriously','old','definitely','ready',\n",
    "    'season','join','tomorrow','mean','actually','kinda','wow'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56db2c43",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (3407689837.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/z4/_1f_7w7d7l77xjjqsqqpzx600000gn/T/ipykernel_74104/3407689837.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    STOPWORDS.union(open(r'/Users/zengspencer/Desktop/bad-words.txt')\u001b[0m\n\u001b[0m                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "STOPWORDS.union(open(r'/Users/zengspencer/Desktop/bad-words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'/Users/zengspencer/Desktop/emogen_mask_70.csv')\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4510a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb555ea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c1_25 = labels.head(25).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d96e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c26_51 = labels.tail(26).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b074fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c1_25:\n",
    "    X = df[y.str.contains(i)]['Class_Text']\n",
    "    vec = TfidfVectorizer()\n",
    "    x_m = vec.fit_transform(X.values.astype('U'))\n",
    "    freqs = {word : x_m.getcol(idx).sum() for word, idx in vec.vocabulary_.items()}\n",
    "    wc = WordCloud(\n",
    "    stopwords = STOPWORDS,\n",
    "    width=1170,\n",
    "    height=600,\n",
    "    background_color='white',\n",
    "    max_words=2000).fit_words({a:b for a, b in freqs.items() if a not in STOPWORDS})\n",
    "    name = i+'.png'\n",
    "    wc.to_file(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
